#                        county_list[i], ".png", sep=''), scale=2)
# save plots as .pdf
# ggsave(plot, file=paste(results,
#                        'projection_graphs/county_graphs/',
#                        county_list[i], ".pdf", sep=''), scale=2)
# print plots to screen
print(plot)
}
}
#Then, we will plot each, but first we will need to reshape the data frame into a long format
ggplot(distributionPerSegment16, aes(unclean_mean_awc, unclean_sd_awc))+
geom_point()
ggplot(distributionPerSegment16, aes(clean_mean_awc, clean_sd_awc))+
geom_point()
ggplot(distributionPerSegment16, aes(x = reorder(SUBJECT, clean_mean_awc),y = clean_mean_awc)) +
geom_bar(stat = "identity",position = "dodge") +
geom_errorbar(width=.1, aes(ymin=clean_mean_awc-clean_sd_awc, ymax=clean_mean_awc+clean_sd_awc)) +
theme_gray()
#Then, we will plot each, but first we will need to reshape the data frame into a long format
ggplot(distributionPerSegment16, aes(unclean_mean_ctc, unclean_sd_ctc))+
geom_point()
ggplot(distributionPerSegment16, aes(clean_mean_ctc, clean_sd_ctc))+
geom_point()
ggplot(distributionPerSegment16, aes(x = reorder(SUBJECT, clean_mean_ctc),y = clean_mean_ctc)) +
geom_bar(stat = "identity",position = "dodge") +
geom_errorbar(width=.1, aes(ymin=clean_mean_ctc-clean_sd_ctc, ymax=clean_mean_ctc+clean_sd_ctc)) +
theme_gray()
#Then, we will plot each, but first we will need to reshape the data frame into a long format
ggplot(distributionPerSegment16, aes(unclean_mean_cvc, unclean_sd_cvc))+
geom_point()
ggplot(distributionPerSegment16, aes(clean_mean_cvc, clean_sd_cvc))+
geom_point()
ggplot(distributionPerSegment16, aes(x = reorder(SUBJECT, clean_mean_cvc),y = clean_mean_cvc)) +
geom_bar(stat = "identity",position = "dodge") +
geom_errorbar(width=.1, aes(ymin=clean_mean_cvc-clean_sd_cvc, ymax=clean_mean_cvc+clean_sd_cvc)) +
theme_gray()
#Then, we will plot each, but first we will need to reshape the data frame into a long format
ggplot(distributionPerHour16, aes(unclean_mean_awc, unclean_sd_awc))+
geom_point()
ggplot(distributionPerHour16, aes(clean_mean_awc, clean_sd_awc))+
geom_point()
ggplot(distributionPerHour16, aes(x = reorder(SUBJECT, clean_mean_awc),y = clean_mean_awc)) +
geom_bar(stat = "identity",position = "dodge") +
geom_errorbar(width=.1, aes(ymin=clean_mean_awc-clean_sd_awc, ymax=clean_mean_awc+clean_sd_awc)) +
theme_gray()
#Then, we will plot each, but first we will need to reshape the data frame into a long format
ggplot(distributionPerHour16, aes(unclean_mean_ctc, unclean_sd_ctc))+
geom_point()
ggplot(distributionPerHour16, aes(clean_mean_ctc, clean_sd_ctc))+
geom_point()
ggplot(distributionPerHour16, aes(x = reorder(SUBJECT, clean_mean_ctc),y = clean_mean_ctc)) +
geom_bar(stat = "identity",position = "dodge") +
geom_errorbar(width=.1, aes(ymin=clean_mean_ctc-clean_sd_ctc, ymax=clean_mean_ctc+clean_sd_ctc)) +
theme_gray()
#Then, we will plot each, but first we will need to reshape the data frame into a long format
ggplot(distributionPerHour16, aes(unclean_mean_cvc, unclean_sd_cvc))+
geom_point()
ggplot(distributionPerHour16, aes(clean_mean_cvc, clean_sd_cvc))+
geom_point()
ggplot(distributionPerHour16, aes(x = reorder(SUBJECT, clean_mean_cvc),y = clean_mean_cvc)) +
geom_bar(stat = "identity",position = "dodge") +
geom_errorbar(width=.1, aes(ymin=clean_mean_cvc-clean_sd_cvc, ymax=clean_mean_cvc+clean_sd_cvc)) +
theme_gray()
talkFrequency <- distributionSumation16 %>%
group_by(hour_bin) %>%
mutate(unclean_avg_awc_across_all_subjects = mean(unclean_total_awc),
unclean_avg_cvc_across_all_subjects = mean(unclean_total_cvc),
unclean_avg_ctc_across_all_subjects = mean(unclean_total_ctc)) %>%
mutate(clean_avg_awc_across_all_subjects = mean(clean_total_awc),
clean_avg_cvc_across_all_subjects = mean(clean_total_cvc),
clean_avg_ctc_across_all_subjects = mean(clean_total_ctc)) %>%
distinct(hour_bin, unclean_avg_awc_across_all_subjects, unclean_avg_cvc_across_all_subjects,
unclean_avg_ctc_across_all_subjects, clean_avg_awc_across_all_subjects, clean_avg_cvc_across_all_subjects
,clean_avg_ctc_across_all_subjects )
ggplot(talkFrequency, aes(x = hour_bin,y = unclean_avg_awc_across_all_subjects)) +
geom_bar(stat = "identity",position = "dodge") +
theme_gray()
ggplot(talkFrequency, aes(x = hour_bin,y = unclean_avg_ctc_across_all_subjects)) +
geom_bar(stat = "identity",position = "dodge") +
theme_gray()
ggplot(talkFrequency, aes(x = hour_bin,y = unclean_avg_cvc_across_all_subjects)) +
geom_bar(stat = "identity",position = "dodge") +
theme_gray()
ggplot(talkFrequency, aes(x = hour_bin,y = clean_avg_awc_across_all_subjects)) +
geom_bar(stat = "identity",position = "dodge") +
theme_gray()
ggplot(talkFrequency, aes(x = hour_bin,y = clean_avg_ctc_across_all_subjects)) +
geom_bar(stat = "identity",position = "dodge") +
theme_gray()
ggplot(talkFrequency, aes(x = hour_bin,y = clean_avg_cvc_across_all_subjects)) +
geom_bar(stat = "identity",position = "dodge") +
theme_gray()
child_dist_per_hour.ordered(distributionSumation16)
## what is the difference between top hour and bottom hour? and what is the mean/proportion maximal difference between hours.
child_dist_per_hour.unordered(distributionSumation16)
## what is the difference between top hour and bottom hour? and what is the mean/proportion maximal difference between hours.
child_dist_per_seg.ordered(sotCodingSheet16)
## fix the squigily graph
# is there a relationship between how steep your curve is and the avereage,
# Do steeper people have a higher average overall?
# You have people who are bursty, if you are bursty, do you have a higher average overall or can we decouple burstyness?
# Are there pockets of time while the rest is not as intense.
# Can you be low overall but still be bursty?
# Average, steepness, and burstyness.
child_dist_per_seg.unordered(sotCodingSheet16)
child_dist_per_seg.unordered(sotCodingSheet16)
## fix the squigily graph
# is there a relationship between how steep your curve is and the avereage,
# Do steeper people have a higher average overall?
# You have people who are bursty, if you are bursty, do you have a higher average overall or can we decouple burstyness?
# Are there pockets of time while the rest is not as intense.
# Can you be low overall but still be bursty?
# Average, steepness, and burstyness.
burstySubjectshourly <- hourlyProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
burstySubjectsSeg <- segProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
averagePropDropHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp =1 - mean(prop)) %>%
distinct(averageProp)
averagePropDropHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = 1 - mean(prop)) %>%
distinct(averageProp)
hist(averagePropDropHourly$averageProp)
hist(averagePropDropHourly$averageProp)
#average proportion change per hour
#median split!!!!! Naturally breaks the group in half. \
#The mean could give us.
#are people who are talking more dropping more?
ggplot(averagePropDropHourly, aes(x = averagePropDropHourly$averageProp, y = distributionPerHour16$clean_mean_awc))+
geom_point() +
geom_smooth(method = "lm")
v <- sort(v)
burstySubjectshourly <- hourlyProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
burstySubjectsSeg <- segProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
averagePropRetainmentHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = mean(prop)) %>%
distinct(averageProp)
averagePropDropHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = 1 - mean(prop)) %>%
distinct(averageProp)
hist(averagePropRetainmentHourly$averageProp)
hist(averagePropDropHourly$averageProp)
#average proportion change per hour
#median split!!!!! Naturally breaks the group in half. \
#The mean could give us.
#are people who are talking more dropping more?
ggplot(averagePropDropHourly, aes(x = averagePropDropHourly$averageProp, y = distributionPerHour16$clean_mean_awc))+
geom_point() +
geom_smooth(method = "lm")
View(averagePropRetainmentHourly)
View(averagePropDropHourly)
bottomHalf <- averagePropDropHourly %>%
filter(averageProp < med(averageProp)) %>%
distinct(subject)
bottomHalf <- averagePropDropHourly %>%
filter(averageProp < median(averageProp)) %>%
distinct(subject)
topHalf <- averagePropDropHourly %>%
filter(averageProp >= median(averageProp)) %>%
distinct(subject)
View(bottomHalf)
View(topHalf)
median <- median(averagePropDropHourly$averageProp)
bottomHalf <- averagePropDropHourly %>%
filter(averageProp < median(averageProp)) %>%
distinct(subject)
topHalf <- averagePropDropHourly %>%
filter(averageProp >= median(averageProp)) %>%
distinct(subject)
median <- median(averagePropDropHourly$averageProp)
bottomHalf <- averagePropDropHourly %>%
filter(averageProp < median) %>%
distinct(subject)
topHalf <- averagePropDropHourly %>%
filter(averageProp >= median) %>%
distinct(subject)
View(topHalf)
View(bottomHalf)
View(hourlyProp16)
View(hourlyOrdered16)
View(averagePropDropHourly)
View(distributionSumation16)
View(distributionPerHour16)
View(averagePropDropHourly)
View(distributionPerHour16)
#Then, we will plot each, but first we will need to reshape the data frame into a long format
ggplot(distributionPerSegment16, aes(unclean_mean_awc, unclean_sd_awc))+
geom_point() +
geom_smooth(method = "lm")
ggplot(distributionPerSegment16, aes(clean_mean_awc, clean_sd_awc))+
geom_point() +
geom_smooth(method = "lm")
ggplot(distributionPerSegment16, aes(x = reorder(SUBJECT, clean_mean_awc),y = clean_mean_awc)) +
geom_bar(stat = "identity",position = "dodge") +
geom_errorbar(width=.1, aes(ymin=clean_mean_awc-clean_sd_awc, ymax=clean_mean_awc+clean_sd_awc)) +
theme_gray()
burstySubjectshourly <- hourlyProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
burstySubjectsSeg <- segProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
averagePropRetainmentHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = mean(prop)) %>%
distinct(averageProp)
averagePropDropHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = 1 - mean(prop)) %>%
distinct(averageProp)
hist(averagePropRetainmentHourly$averageProp)
abline(v = Median(averagePropRetainmentHourly$averageProp$averageProp), col = "blue", lwd = 2)
burstySubjectshourly <- hourlyProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
burstySubjectsSeg <- segProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
averagePropRetainmentHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = mean(prop)) %>%
distinct(averageProp)
averagePropDropHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = 1 - mean(prop)) %>%
distinct(averageProp)
hist(averagePropRetainmentHourly$averageProp)
abline(v = median(averagePropRetainmentHourly$averageProp$averageProp), col = "blue", lwd = 2)
burstySubjectshourly <- hourlyProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
burstySubjectsSeg <- segProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
averagePropRetainmentHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = mean(prop)) %>%
distinct(averageProp)
averagePropDropHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = 1 - mean(prop)) %>%
distinct(averageProp)
medPropRet <- averagePropRetainmentHourly %>%
median(averageProp)
burstySubjectshourly <- hourlyProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
burstySubjectsSeg <- segProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
averagePropRetainmentHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = mean(prop)) %>%
distinct(averageProp)
averagePropDropHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = 1 - mean(prop)) %>%
distinct(averageProp)
medPropRet <- averagePropRetainmentHourly %>%
median(as.numeric(averageProp))
View(averagePropRetainmentHourly)
burstySubjectshourly <- hourlyProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
burstySubjectsSeg <- segProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
averagePropRetainmentHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = mean(prop)) %>%
distinct(averageProp)
averagePropDropHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = 1 - mean(prop)) %>%
distinct(averageProp)
medPropRet <- averagePropRetainmentHourly %>%
median(averageProp)
burstySubjectshourly <- hourlyProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
burstySubjectsSeg <- segProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
averagePropRetainmentHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = mean(prop)) %>%
distinct(averageProp)
averagePropDropHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = 1 - mean(prop)) %>%
distinct(averageProp)
medPropRet <-  median(averagePropRetainmentHourly[1])
burstySubjectshourly <- hourlyProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
burstySubjectsSeg <- segProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
averagePropRetainmentHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = mean(prop)) %>%
distinct(averageProp)
averagePropDropHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = 1 - mean(prop)) %>%
distinct(averageProp)
str(averagePropDropHourly)
hist(averagePropRetainmentHourly$averageProp)
abline(v = medPropRet, col = "blue", lwd = 2)
burstySubjectshourly <- hourlyProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
burstySubjectsSeg <- segProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
averagePropRetainmentHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = mean(prop)) %>%
distinct(averageProp)
averagePropDropHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = 1 - mean(prop)) %>%
distinct(averageProp)
hist(averagePropRetainmentHourly$averageProp)
hist(averagePropDropHourly$averageProp)
#average proportion change per hour
#median split!!!!! Naturally breaks the group in half. \
#The mean could give us.
#are people who are talking more dropping more?
ggplot(averagePropDropcHourly, aes(x = averagePropDropHourly$averageProp, y = distributionPerHour16$clean_mean_awc))+
geom_point() +
geom_smooth(method = "lm")
burstySubjectshourly <- hourlyProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
burstySubjectsSeg <- segProp16 %>%
group_by(subject) %>%
filter(prop < .50) %>%
mutate(subjects = subject) %>%
distinct(subject)
averagePropRetainmentHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = mean(prop)) %>%
distinct(averageProp)
averagePropDropHourly <- hourlyProp16 %>%
group_by(subject) %>%
mutate(averageProp = 1 - mean(prop)) %>%
distinct(averageProp)
hist(averagePropRetainmentHourly$averageProp)
hist(averagePropDropHourly$averageProp)
#average proportion change per hour
#median split!!!!! Naturally breaks the group in half. \
#The mean could give us.
#are people who are talking more dropping more?
ggplot(averagePropDropHourly, aes(x = averagePropDropHourly$averageProp, y = distributionPerHour16$clean_mean_awc))+
geom_point() +
geom_smooth(method = "lm")
View(distributionSumation16)
View(distributionPerSegment16)
View(distributionHourBin16)
View(cleanedSotCodingSheet16)
View(distributionHourBin16)
View(distributionPerHour16)
---
title: "Cleaning and Tidying Data"
author: "Joel Ramirez Jr"
date: "5/20/2020"
output: html_document
---
library(tidyverse)
library(readxl)
# csv files
TL3Metadata <- read_csv("TL3Data/TL3data.csv")
sotCodingSheet16 <- read_csv("TL3Data/SOT_NEW16FIXED.csv")
sotCodingSheet18 <- read_csv("TL3Data/SOT_NEW18FIXED.csv")
# grabbing the neccesary files
# sotCodingSheet16 <- sotCodingSheet16[c(1:23, 47)]
# sotCodingSheet18 <- sotCodingSheet18[c(1:23, 47)]
sotCodingSheet16 <- sotCodingSheet16[c(1:23)]
sotCodingSheet18 <- sotCodingSheet18[c(1:23)]
TL3MetadataRenamed = TL3Metadata %>%
rename(
SUBJECT = "SubjectID1 Subject #",
SEX = "Sex Sex",
ETHNICITY = "Ethnicity Ethnicity",
MOM_YRS_EDU = "MomEdu Mom yrs. Education",
SES = "HI_SES",
CDI_18C16C_WG = "CDIPDEV18CTL316CWSWGprodUSE PDEV18CTL316C WS prod scores converted to WG & original WG prod scores USE",
CDI_18C16C_WG_PERCENTILE = "CDIPDEV18CTL316CWSWGProdPtileUSE",
CDI_18C18C_WG = "CDIPDEV18CTL318CWSWGprodUSE PDEV18CTL318C WS prod scores converted to WG & original WG prod scores USE",
CDI_18C18C_WG_PERCENTILE = "CDIPDEV18CTL318CWSWGprodptileUSE",
AWCr_1818   = LENAPDEV18CTL318CAWCHr,
CTCHr_1818  = LENAPDEV18CTL318CCTCHr,
CVCHr_1818  = LENAPDEV18CTL318CCVCHr,
ACC_1816    = "A18C16C acc for participants with > or = 25% of total trials for accuracy (.25*64 = 16 trials)",
RT_1816     = RT18C16C,
ACC_1818 = "A18A18C acc for participants with > or = 25% of total trials for accuracy (.25*64 = 16 trials)"
)
sotCodingSheet16 <- sotCodingSheet16%>%
select(-Firstname) %>%
rename(SUBJECT = Lastname)
sotCodingSheet18 <- sotCodingSheet18%>%
select(-Firstname) %>%
rename(SUBJECT = Lastname)
TL3MetadataRenamed = TL3Metadata %>%
rename(
SUBJECT = "SubjectID1 Subject #",
SEX = "Sex Sex",
ETHNICITY = "Ethnicity Ethnicity",
MOM_YRS_EDU = "MomEdu Mom yrs. Education",
SES = "HI_SES",
CDI_18C16C_WG = "CDIPDEV18CTL316CWSWGprodUSE PDEV18CTL316C WS prod scores converted to WG & original WG prod scores USE",
CDI_18C16C_WG_PERCENTILE = "CDIPDEV18CTL316CWSWGProdPtileUSE",
sf
w22
.rs.restartR()
```{r, echo=FALSE}
library(knitr)
source('~/Desktop/profiles/1.Data Restructuring/fixedDataWrangling.R', echo=TRUE)
title: "Cleaning and Tidying Data"
source('~/Desktop/profiles/1.Data Restructuring/fixedDataWrangling.R', echo=TRUE)
title: "Cleaning and Tidying Data"
library(readxl)
```
## Load necessary sheets and csv's
```{r, echo=FALSE}
---
title: "Cleaning and Tidying Data"
author: "Joel Ramirez Jr"
date: "5/20/2020"
output: html_document
---
```{r, echo=FALSE}
library(knitr)
opts_chunk$set(echo=TRUE,
warning=FALSE, message=FALSE,
cache=FALSE)
```
## Load libraries
```{r}
library(tidyverse)
library(readxl)
```
## Load necessary sheets and csv's
```{r, echo=FALSE}
# csv files
TL3Metadata <- read_csv("TL3Data/TL3data.csv")
sotCodingSheet16 <- read_csv("TL3Data/SOT_NEW16FIXED.csv")
sotCodingSheet18 <- read_csv("TL3Data/SOT_NEW18FIXED.csv")
# grabbing the neccesary files
# sotCodingSheet16 <- sotCodingSheet16[c(1:23, 47)]
# sotCodingSheet18 <- sotCodingSheet18[c(1:23, 47)]
sotCodingSheet16 <- sotCodingSheet16[c(1:23)]
sotCodingSheet18 <- sotCodingSheet18[c(1:23)]
source('~/Desktop/profiles/1.Data Restructuring/fixedDataWrangling.R', echo=TRUE)
install.packages("tidyverse")
---
title: "Cleaning and Tidying Data"
author: "Joel Ramirez Jr"
