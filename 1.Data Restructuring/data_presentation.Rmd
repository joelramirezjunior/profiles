---
title: "dataAnalysis"
author: "Joel Ramirez Jr"
date: "7/1/2020"
output: html_document
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(readxl)
library(ppcor)
library(gridExtra)
```

```{r}
child_dist_per_hour.ordered <- function(df, na.rm = TRUE, ...){
  
  # create list of counties in data to loop over 
  subject_list <- unique(distributionPerHour16$SUBJECT)
  # create for loop to produce ggplot2 graphs 
  for (i in seq_along(subject_list)) { 
    
    # create plot for each subject in df 
    cur_df <- df %>% 
      filter(SUBJECT == subject_list[i])
    
    plot <- 
      ggplot(cur_df, aes( x = as.numeric(reorder(hour_bin, clean_total_awc)),
                          y = as.numeric(clean_total_awc) )) +
      ylim(0.0, 7000.0) +
    geom_bar(stat = "identity",position = "dodge") +
      theme_gray() +
      ggtitle(paste( "Subject", subject_list[i], 'Hourly Caregiver Talk',
                    sep=''))
    # save plots as .png
    # ggsave(plot, file=paste(results, 
    #                        'projection_graphs/county_graphs/',
    #                        county_list[i], ".png", sep=''), scale=2)
   
    # save plots as .pdf
    # ggsave(plot, file=paste(results, 
    #                        'projection_graphs/county_graphs/',
    #                        county_list[i], ".pdf", sep=''), scale=2)
    
    # print plots to screen
    print(plot)
  }
}

child_dist_per_hour.unordered <- function(df, na.rm = TRUE, ...){
  
  # create list of counties in data to loop over 
  subject_list <- unique(distributionPerHour16$SUBJECT)
  # create for loop to produce ggplot2 graphs 
  for (i in seq_along(subject_list)) { 
    
    # create plot for each subject in df 
    cur_df <- df %>% 
      filter(SUBJECT == subject_list[i])
    
    plot <- 
      ggplot(cur_df, aes( x = hour_bin,
                          y = clean_total_awc)) +
      ylim(0.0, 7000.0) +
    geom_bar(stat = "identity",position = "dodge") +
      theme_gray() +
      ggtitle(paste( "Subject", subject_list[i], 'Hourly Caregiver Talk',
                    sep=''))
    # save plots as .png
    # ggsave(plot, file=paste(results, 
    #                        'projection_graphs/county_graphs/',
    #                        county_list[i], ".png", sep=''), scale=2)
   
    # save plots as .pdf
    # ggsave(plot, file=paste(results, 
    #                        'projection_graphs/county_graphs/',
    #                        county_list[i], ".pdf", sep=''), scale=2)
    
    # print plots to screen
    print(plot)
  }
}

child_dist_per_seg.ordered <- function(df, na.rm = TRUE, ...){
  
  # create list of counties in data to loop over 
  subject_list <- unique(distributionPerHour16$SUBJECT)
  # create for loop to produce ggplot2 graphs 
  for (i in seq_along(subject_list)) { 
    
    # create plot for each subject in df 
    
    cur_df <- df %>% 
      filter(SUBJECT == subject_list[i])
    
    plot <- 
      ggplot(cur_df, aes( x = as.numeric(reorder(Time, AWC)),
                          y = as.numeric(AWC) )) +
    geom_bar(stat = "identity",position = "dodge") +
      theme_gray() +
      ggtitle(paste( "Subject ", subject_list[i], ' Per Segment Caregiver Talk',
                    sep=''))
    # save plots as .png
    # ggsave(plot, file=paste(results, 
    #                        'projection_graphs/county_graphs/',
    #                        county_list[i], ".png", sep=''), scale=2)
   
    # save plots as .pdf
    # ggsave(plot, file=paste(results, 
    #                        'projection_graphs/county_graphs/',
    #                        county_list[i], ".pdf", sep=''), scale=2)
    
    # print plots to screen
    print(plot)
  }
}

child_dist_per_seg.unordered <- function(df, na.rm = TRUE, ...){
  
  # create list of counties in data to loop over 
  subject_list <- unique(distributionPerHour16$SUBJECT)
  # create for loop to produce ggplot2 graphs 
  for (i in seq_along(subject_list)) { 
    
    # create plot for each subject in df 
    cur_df <- df %>% 
      filter(SUBJECT == subject_list[i])
    
    plot <- 
      ggplot(cur_df, aes( x = as.numeric(Time),
                          y = as.numeric(AWC) )) +
      ylim(0.0, 500.0) +
    geom_bar(stat = "identity",position = "dodge") +
      theme_gray() +
      ggtitle(paste( "Subject ", subject_list[i], ' Per Segment Caregiver Talk',
                    sep=''))
    # save plots as .png
    # ggsave(plot, file=paste(results, 
    #                        'projection_graphs/county_graphs/',
    #                        county_list[i], ".png", sep=''), scale=2)
   
    # save plots as .pdf
    # ggsave(plot, file=paste(results, 
    #                        'projection_graphs/county_graphs/',
    #                        county_list[i], ".pdf", sep=''), scale=2)
    
    # print plots to screen
    print(plot)
  }
}

```


## Distribution Per Segment 16 Months!
## AWC
```{r cars}
#Then, we will plot each, but first we will need to reshape the data frame into a long format
ggplot(distributionPerHour16, aes(unclean_mean_awc, unclean_sd_awc))+
  geom_point() +
   geom_smooth(method = "lm")



ggplot(distributionPerHour16, aes(clean_mean_awc, clean_sd_awc))+
  geom_point() +
   geom_smooth(method = "lm")

cor(distributionPerHour16, method = c("pearson"))


ggplot(distributionPerSegment16, aes(x = reorder(SUBJECT, clean_mean_awc),y = clean_mean_awc)) +
    geom_bar(stat = "identity",position = "dodge") +
  geom_errorbar(width=.1, aes(ymin=clean_mean_awc-clean_sd_awc, ymax=clean_mean_awc+clean_sd_awc)) +
  
  theme_gray()
```




#CTC
```{r cars}
#Then, we will plot each, but first we will need to reshape the data frame into a long format
ggplot(distributionPerSegment16, aes(unclean_mean_ctc, unclean_sd_ctc))+
  geom_point()

ggplot(distributionPerSegment16, aes(clean_mean_ctc, clean_sd_ctc))+
  geom_point()

ggplot(distributionPerSegment16, aes(x = reorder(SUBJECT, clean_mean_ctc),y = clean_mean_ctc)) +
    geom_bar(stat = "identity",position = "dodge") +
  geom_errorbar(width=.1, aes(ymin=clean_mean_ctc-clean_sd_ctc, ymax=clean_mean_ctc+clean_sd_ctc)) +
  theme_gray()
```

#CVC
```{r cars}
#Then, we will plot each, but first we will need to reshape the data frame into a long format
ggplot(distributionPerSegment16, aes(unclean_mean_cvc, unclean_sd_cvc))+
  geom_point()

ggplot(distributionPerSegment16, aes(clean_mean_cvc, clean_sd_cvc))+
  geom_point()

ggplot(distributionPerSegment16, aes(x = reorder(SUBJECT, clean_mean_cvc),y = clean_mean_cvc)) +
    geom_bar(stat = "identity",position = "dodge") +
  geom_errorbar(width=.1, aes(ymin=clean_mean_cvc-clean_sd_cvc, ymax=clean_mean_cvc+clean_sd_cvc)) +
  theme_gray()
```



## Distribution Per Hour 16 Months!
## AWC
```{r cars}
#Then, we will plot each, but first we will need to reshape the data frame into a long format
ggplot(distributionPerHour16, aes(unclean_mean_awc, unclean_sd_awc))+
  geom_point()

ggplot(distributionPerHour16, aes(clean_mean_awc, clean_sd_awc))+
  geom_point()

ggplot(distributionPerHour16, aes(x = reorder(SUBJECT, clean_mean_awc),y = clean_mean_awc)) +
    geom_bar(stat = "identity",position = "dodge") +
  geom_errorbar(width=.1, aes(ymin=clean_mean_awc-clean_sd_awc, ymax=clean_mean_awc+clean_sd_awc)) +
  theme_gray()
```




#CTC
```{r cars}
#Then, we will plot each, but first we will need to reshape the data frame into a long format
ggplot(distributionPerHour16, aes(unclean_mean_ctc, unclean_sd_ctc))+
  geom_point()

ggplot(distributionPerHour16, aes(clean_mean_ctc, clean_sd_ctc))+
  geom_point()

ggplot(distributionPerHour16, aes(x = reorder(SUBJECT, clean_mean_ctc),y = clean_mean_ctc)) +
    geom_bar(stat = "identity",position = "dodge") +
  geom_errorbar(width=.1, aes(ymin=clean_mean_ctc-clean_sd_ctc, ymax=clean_mean_ctc+clean_sd_ctc)) +
  theme_gray()
```

#CVC
```{r cars}
#Then, we will plot each, but first we will need to reshape the data frame into a long format
ggplot(distributionPerHour16, aes(unclean_mean_cvc, unclean_sd_cvc))+
  geom_point()

ggplot(distributionPerHour16, aes(clean_mean_cvc, clean_sd_cvc))+
  geom_point()

ggplot(distributionPerHour16, aes(x = reorder(SUBJECT, clean_mean_cvc),y = clean_mean_cvc)) +
    geom_bar(stat = "identity",position = "dodge") +
  geom_errorbar(width=.1, aes(ymin=clean_mean_cvc-clean_sd_cvc, ymax=clean_mean_cvc+clean_sd_cvc)) +
  theme_gray()
```




## Where is talk happening?
```{r}
talkFrequency <- distributionSumation16 %>% 
  group_by(hour_bin) %>% 
   mutate(unclean_avg_awc_across_all_subjects = mean(unclean_total_awc),
         unclean_avg_cvc_across_all_subjects = mean(unclean_total_cvc),
         unclean_avg_ctc_across_all_subjects = mean(unclean_total_ctc)) %>% 
  
  mutate(clean_avg_awc_across_all_subjects = mean(clean_total_awc),
         clean_avg_cvc_across_all_subjects = mean(clean_total_cvc),
         clean_avg_ctc_across_all_subjects = mean(clean_total_ctc)) %>% 
  distinct(hour_bin, unclean_avg_awc_across_all_subjects, unclean_avg_cvc_across_all_subjects,
           unclean_avg_ctc_across_all_subjects, clean_avg_awc_across_all_subjects, clean_avg_cvc_across_all_subjects
           ,clean_avg_ctc_across_all_subjects )
```

#unclean lena frequency diagrams
```{r}
ggplot(talkFrequency, aes(x = hour_bin,y = unclean_avg_awc_across_all_subjects)) +
    geom_bar(stat = "identity",position = "dodge") +
  theme_gray()


ggplot(talkFrequency, aes(x = hour_bin,y = unclean_avg_ctc_across_all_subjects)) +
    geom_bar(stat = "identity",position = "dodge") +
  theme_gray()

ggplot(talkFrequency, aes(x = hour_bin,y = unclean_avg_cvc_across_all_subjects)) +
    geom_bar(stat = "identity",position = "dodge") +
  theme_gray()
```
#check 5 am cvc values, there is only one child at 5am, group with 6?


#clean lena frequency diagrams
```{r}
ggplot(talkFrequency, aes(x = hour_bin,y = clean_avg_awc_across_all_subjects)) +
    geom_bar(stat = "identity",position = "dodge") +
  theme_gray()


ggplot(talkFrequency, aes(x = hour_bin,y = clean_avg_ctc_across_all_subjects)) +
    geom_bar(stat = "identity",position = "dodge") +
  theme_gray()

ggplot(talkFrequency, aes(x = hour_bin,y = clean_avg_cvc_across_all_subjects)) +
    geom_bar(stat = "identity",position = "dodge") +
  theme_gray()
```




```{r}
child_dist_per_hour.ordered(distributionSumation16)
## what is the difference between top hour and bottom hour? and what is the mean/proportion maximal difference between hours. 



```

```{r}
child_dist_per_hour.unordered(distributionSumation16)
## what is the difference between top hour and bottom hour? and what is the mean/proportion maximal difference between hours. 
```


```{r}
child_dist_per_seg.ordered(sotCodingSheet16)

## fix the squigily graph

# is there a relationship between how steep your curve is and the avereage,
# Do steeper people have a higher average overall?
# You have people who are bursty, if you are bursty, do you have a higher average overall or can we decouple burstyness? 
# Are there pockets of time while the rest is not as intense.
# Can you be low overall but still be bursty?
# Average, steepness, and burstyness. 

child_dist_per_seg.unordered(sotCodingSheet16)

```

```{r}
child_dist_per_seg.unordered(sotCodingSheet16)

## fix the squigily graph

# is there a relationship between how steep your curve is and the avereage,
# Do steeper people have a higher average overall?
# You have people who are bursty, if you are bursty, do you have a higher average overall or can we decouple burstyness? 
# Are there pockets of time while the rest is not as intense.
# Can you be low overall but still be bursty?


# Average, steepness, and burstyness. 

```



#Do we want to see if the prop<some number if more significant?
```{r}

subjectPropDrop <- hourlyProp16 %>% 
  group_by(SUBJECT) %>% 
  mutate(propDrop = 1-prop) %>% 
  mutate(avgHourlyPropDrop = mean(propDrop), maxPropDrop = max(propDrop), minPropDrop = min(propDrop)) %>% 
  distinct(avgHourlyPropDrop, maxPropDrop, minPropDrop)


hourlyDist16 <- merge(subjectPropDrop, distributionPerHour16, by = 'SUBJECT')

hist(subjectPropDrop$avgHourlyPropDrop)

#average proportion change per hour
#median split!!!!! Naturally breaks the group in half. \
#The mean could give us. 

#are people who are talking more dropping more? 


ggplot(hourlyDist16, aes(x = avgHourlyPropDrop, y = clean_mean_awc))+
  geom_point() + 
  geom_smooth(method = "lm")

ggplot(hourlyDist16, aes(x = avgHourlyPropDrop, y = clean_sd_awc))+
  geom_point() + 
  geom_smooth(method = "lm")

ggplot(hourlyDist16, aes(x = maxPropDrop, y = clean_mean_awc))+
  geom_point() + 
  geom_smooth(method = "lm")

ggplot(hourlyDist16, aes(x = maxPropDrop, y = clean_sd_awc))+
  geom_point() + 
  geom_smooth(method = "lm")


ggplot(hourlyDist16, aes(x = minPropDrop, y = clean_mean_awc))+
  geom_point() + 
  geom_smooth(method = "lm")

ggplot(hourlyDist16, aes(x = minPropDrop, y = clean_sd_awc))+
  geom_point() + 
  geom_smooth(method = "lm")

```




```{r}

#some people can be steepy and low and some people can be steepy and high
#some people can be grad and low and some people can be grad and high
#What does all day AWC mean?? High awc means ppl talk all the time??? nah, it's just an average accross the day
#people are variable from moment to moment and talk about the shape of the overall dist, with bursty and gradual people
#some people have a biggere difference on average between each 5 minute segment
#DREW ABNEY (LITERATURE ON BURSTYNESS)
#START A TIMELINE FOR DEADLINES
#SRCD BI ANNUAL CONFERENCE ABOUT FAMILY MATTERS 
#start back, from the start with AWC and what it means.
#then get to the peakyness and awc 
#go back to the casillas paper, with how can people learn from nothing? 
#the nothing is defined from very low talk (on average)
#are there peaks of intense language?

#where we are at is not an easy place to be at, so use some graphics and make it easier to understand!cisc
#Then, we will plot each, but first we will need to reshape the data frame into a long format


ggplot(distributionPerSegment16, aes(unclean_mean_ctc, unclean_sd_ctc))+
  geom_point()

ggplot(distributionPerSegment16, aes(clean_mean_ctc, clean_sd_ctc))+
  geom_point()

ggplot(distributionPerSegment16, aes(x = reorder(SUBJECT, clean_mean_ctc),y = clean_mean_ctc)) +
    geom_bar(stat = "identity",position = "dodge") +
  geom_errorbar(width=.1, aes(ymin=clean_mean_ctc-clean_sd_ctc, ymax=clean_mean_ctc+clean_sd_ctc)) +
  theme_gray()

english <- sotCodingSheet16 %>% 
  replace_na(list(Exclude = "keep")) %>% 
  replace_na(list(DNL = "0")) %>% 
  replace_na(list(Sleep = "0"))

date_seq <- english %>% 
  group_by(SUBJECT, Date) %>% 
  distinct(Date) %>% 
  group_by(SUBJECT) %>% 
  arrange(Date) %>% 
  mutate(date_seq = seq_len(n()))

english2 <- english %>% 
  full_join(date_seq, by = c("SUBJECT", "Date"))


hours_rec_uncleaned_full_recording <- english2 %>% 
  group_by(SUBJECT) %>% 
  mutate(hours_rec_uncleaned_full_recording = sum(Duration)/3600) %>% 
  distinct(SUBJECT, hours_rec_uncleaned_full_recording)

ggplot(hours_rec_uncleaned_full_recording, aes(hours_rec_uncleaned_full_recording)) + 
  geom_histogram() 

english <- english %>% 
 filter(SUBJECT < 911000)

ggplot(english, aes(Time, SUBJECT)) +
  geom_point()
```


```{r}

clusterAndDistrubtionMeasures <- merge(clusterValue, hourlyDist16, by = 'SUBJECT')

clusterAndDistrubtionMeasures <- clusterAndDistrubtionMeasures %>% 
  mutate(clusterPerHr = nclusters/clean_total_hrs) 

clusterAndDistrubtionMeasures <- merge(clusterAndDistrubtionMeasures, TL3MetadataRenamed, by = 'SUBJECT')


ggplot(clusterAndDistrubtionMeasures, aes(clusterPerHr, clean_mean_awc))+
  geom_point() +
  geom_smooth(method = "lm")

cor.test(clusterAndDistrubtionMeasures$clusterPerHr, clusterAndDistrubtionMeasures$clean_mean_awc, method = c("pearson"))

ggplot(clusterAndDistrubtionMeasures, aes(clusterPerHr, clean_sd_awc))+
  geom_point() +
  geom_smooth(method = "lm")

cor.test(clusterAndDistrubtionMeasures$clusterPerHr, clusterAndDistrubtionMeasures$clean_sd_awc, method = c("pearson"))

ggplot(clusterAndDistrubtionMeasures, aes(clean_mean_awc, clean_sd_awc))+
  geom_point() +
  geom_smooth(method = "lm")

cor.test(clusterAndDistrubtionMeasures$clean_mean_awc, clusterAndDistrubtionMeasures$clean_sd_awc, method = c("pearson"))

ggplot(clusterAndDistrubtionMeasures, aes(avgclustersize, clean_mean_awc))+
  geom_point() +
  geom_smooth(method = "lm")
cor.test(clusterAndDistrubtionMeasures$avgclustersize, clusterAndDistrubtionMeasures$clean_mean_awc, method = c("pearson"))


ggplot(clusterAndDistrubtionMeasures, aes(avgclustersize, nclusters))+
  geom_point() +
  geom_smooth(method = "lm")
cor.test(clusterAndDistrubtionMeasures$avgclustersize, clusterAndDistrubtionMeasures$clean_sd_awc, method = c("pearson"))


```



```{r}
#Then, we will plot each, but first we will need to reshape the data frame into a long format
ggplot(clusterAndDistrubtionMeasures, aes(nclusters, clean_mean_awc))+
  geom_point() +
  geom_smooth(method = "lm")

cor.test(clusterAndDistrubtionMeasures$nclusters, clusterAndDistrubtionMeasures$clean_mean_awc, method = c("pearson"))


ggplot(clusterAndDistrubtionMeasures, aes(nclusters, clean_sd_awc))+
  geom_point() +
   geom_smooth(method = "lm")

ggplot(clusterAndDistrubtionMeasures, aes(nclusters, clean_total_hrs))+
  geom_point() +
   geom_smooth(method = "lm")

pcor.test(clusterAndDistrubtionMeasures$clean_mean_awc, clusterAndDistrubtionMeasures$avgclustersize, clusterAndDistrubtionMeasures$clean_total_hrs, method = c("pearson"))

ggplot(clusterAndDistrubtionMeasures, aes(avgclustersize, clean_mean_awc))+
  geom_point() +
  geom_smooth(method = "lm")



ggplot(clusterAndDistrubtionMeasures, aes(avgclustersize, clean_sd_awc))+
  geom_point() +
   geom_smooth(method = "lm")


ggplot(clusterAndDistrubtionMeasures, aes(avgclustersize, clean_total_hrs))+
  geom_point() +
  geom_smooth(method = "lm")



#Predicting to Mean AWC 
model1 = lm(clean_mean_awc ~ nclusters, data = clusterAndDistrubtionMeasures)
summary(model1)

model2 = lm(clean_mean_awc ~ nclusters + clean_total_hrs, data = clusterAndDistrubtionMeasures) 
summary(model2)

model3 = lm(clean_mean_awc ~ avgclustersize + clean_total_hrs, data = clusterAndDistrubtionMeasures) 
summary(model3)


##predicting to cdi
model1 = lm(CDI_18C18C_WG ~ clean_mean_awc , data = clusterAndDistrubtionMeasures)
summary(model1)

model2 = lm(CDI_18C18C_WG ~ clean_mean_awc + clusterPerHr, data = clusterAndDistrubtionMeasures)
summary(model2)


##Predicting to RT 
model4 = lm(RT18A18C_NO1RT ~ clean_mean_awc , data = clusterAndDistrubtionMeasures)
summary(model4)

model5 = lm(RT18A18C_NO1RT ~ clean_mean_awc + clusterPerHr, data = clusterAndDistrubtionMeasures)
summary(model5)


#Predictin to ACC
model6 = lm(ACC_1818 ~ clean_mean_awc , data = clusterAndDistrubtionMeasures)
summary(model6)

model7 = lm(ACC_1818 ~ clean_mean_awc + clusterPerHr, data = clusterAndDistrubtionMeasures)
summary(model7)

## Predicting to CDI only Clean Mean AWC

model1 = lm(CDI_18C18C_WG ~ clean_mean_awc , data = clusterAndDistrubtionMeasures)
summary(model1)

model2 = lm(CDI_18C18C_WG ~ clean_mean_awc + clean_sd_awc, data = clusterAndDistrubtionMeasures)
summary(model2)

## Predicting to RT only Clean Mean AWC
model4 = lm(RT18A18C_NO1RT ~ clean_mean_awc , data = clusterAndDistrubtionMeasures)
summary(model4)

model5 = lm(RT18A18C_NO1RT ~ clean_mean_awc + clean_sd_awc, data = clusterAndDistrubtionMeasures)
summary(model5)


## Predicting to RT only Clean Mean AWC
model6 = lm(ACC_1818 ~ clean_mean_awc , data = clusterAndDistrubtionMeasures)
summary(model6)

model7 = lm(ACC_1818 ~ clean_mean_awc + clean_sd_awc, data = clusterAndDistrubtionMeasures)
summary(model7)



summary(model7)
#using anova

anova(model1, model2)

```
##the more times you pop up with 5 minute seg that are above the 70th percentile then ##srcd is a  big conf in child dev, virtual, next april. this project figure out 
##predicting to outcomes, which of these factors if anything is a better predictor of CDI and RT 
##linear model of child outcomes as a function of AWC clutser size and cluster number, controling for recording length
##if any of those other three pop up controlling for the other things, then they must be adding to the piece of the pie indep.
##TUESDAY 11 OCLOCK
##I WILL HAVE THE DROP VARIABLE AND WE WILL FIGURE OUT A STORY
##These variables are adding new stuff to the story?? 
##what is more predictive? Clusters more predictive for CDI
## further analysis


```{r}
ggplot(clusterAndDistrubtionMeasures, aes(avgHourlyPropDrop, clean_mean_awc))+
  geom_point() +
  geom_smooth(method = "lm")

ggplot(clusterAndDistrubtionMeasures, aes(avgHourlyPropDrop, clean_sd_awc))+
  geom_point() +
   geom_smooth(method = "lm")

ggplot(clusterAndDistrubtionMeasures, aes(avgHourlyPropDrop, CDI_18C18C_WG))+
  geom_point() +
  geom_smooth(method = "lm")

ggplot(clusterAndDistrubtionMeasures, aes(avgHourlyPropDrop, RT18A18C_NO1RT))+
  geom_point() +
   geom_smooth(method = "lm")


ggplot(clusterAndDistrubtionMeasures, aes(avgHourlyPropDrop, ACC_1818))+
  geom_point() +
   geom_smooth(method = "lm")

cor.test(clusterAndDistrubtionMeasures$avgHourlyPropDrop, clusterAndDistrubtionMeasures$CDI_18C18C_WG, method = c("pearson"))
cor.test(clusterAndDistrubtionMeasures$avgHourlyPropDrop, clusterAndDistrubtionMeasures$RT18A18C_NO1RT, method = c("pearson"))
cor.test(clusterAndDistrubtionMeasures$avgHourlyPropDrop, clusterAndDistrubtionMeasures$ACC_1818, method = c("pearson"))





```




```{r}
ggplot(clusterAndDistrubtionMeasures, aes(clusterPerHr, clean_mean_awc))+
  geom_point() +
  geom_smooth(method = "lm")

ggplot(clusterAndDistrubtionMeasures, aes(clusterPerHr, clean_sd_awc))+
  geom_point() +
   geom_smooth(method = "lm")

clusterXCDI <- ggplot(clusterAndDistrubtionMeasures, aes(clusterPerHr, CDI_18C18C_WG))+
  geom_point() +
  geom_smooth(method = "lm") +
   ggtitle("Predicting to Vocabulary at 18 Months") +
  xlab("Clusters per Hour at 16 Months") + ylab("CDI score at 18 Months")

ggsave("clusterXCDI.png",dpi=600)



clusterXACC <- ggplot(clusterAndDistrubtionMeasures, aes(clusterPerHr, ACC_1818))+
  geom_point() +
   geom_smooth(method = "lm")+ 
  ggtitle("Predicting to Accuracy at 18 Months") +
  xlab("Clusters per Hour at 16 Months") + ylab("Acurracy at 18 Months")

grid.arrange(clusterXACC, clusterXCDI, ncol=2)

ggsave("awesomeGraphs.JPEG", dpi=600)


ggplot(clusterAndDistrubtionMeasures, aes(clusterPerHr, RT18A18C_NO1RT))+
  geom_point() +
   geom_smooth(method = "lm")



cor.test(clusterAndDistrubtionMeasures$clusterPerHr, clusterAndDistrubtionMeasures$CDI_18C18C_WG, method = c("pearson"))
cor.test(clusterAndDistrubtionMeasures$clusterPerHr, clusterAndDistrubtionMeasures$RT18A18C_NO1RT, method = c("pearson"))
cor.test(clusterAndDistrubtionMeasures$clusterPerHr, clusterAndDistrubtionMeasures$ACC_1818, method = c("pearson"))


##predicting to cdi
model1 = lm(CDI_18C18C_WG ~ clean_mean_awc , data = clusterAndDistrubtionMeasures)
summary(model1)

model2 = lm(CDI_18C18C_WG ~ clusterPerHr, data = clusterAndDistrubtionMeasures)
summary(model2)

model3 = lm(CDI_18C18C_WG ~ clean_mean_awc + clusterPerHr, data = clusterAndDistrubtionMeasures)
summary(model3)


##Predicting to RT 
model4 = lm(RT18A18C_NO1RT ~ clean_mean_awc , data = clusterAndDistrubtionMeasures)
summary(model4)

model5 = lm(RT18A18C_NO1RT ~ clusterPerHr, data = clusterAndDistrubtionMeasures)
summary(model5)

model6 = lm(RT18A18C_NO1RT ~ clean_mean_awc + clusterPerHr, data = clusterAndDistrubtionMeasures)
summary(model6)

#Predicting to ACC
model4 = lm(ACC_1818 ~ clean_mean_awc , data = clusterAndDistrubtionMeasures)
summary(model4)

model5 = lm(ACC_1818 ~ clusterPerHr, data = clusterAndDistrubtionMeasures)
summary(model5)

model6 = lm(ACC_1818 ~ clean_mean_awc + clusterPerHr, data = clusterAndDistrubtionMeasures)
summary(model6)



ggplot(clusterAndDistrubtionMeasures, aes(clusterPerHr, avgHourlyPropDrop))+
  geom_point() +
   geom_smooth(method = "lm")

```

```{r}
ggplot(clusterAndDistrubtionMeasures, aes(maxPropDrop, clean_mean_awc))+
  geom_point() +
  geom_smooth(method = "lm")

ggplot(clusterAndDistrubtionMeasures, aes(maxPropDrop, clean_sd_awc))+
  geom_point() +
   geom_smooth(method = "lm")

ggplot(clusterAndDistrubtionMeasures, aes(maxPropDrop, ACC_1818))+
  geom_point() +
  geom_smooth(method = "lm")

ggplot(clusterAndDistrubtionMeasures, aes(maxPropDrop, RT18A18C_NO1RT))+
  geom_point() +
   geom_smooth(method = "lm")
```

```{r}


##predicting to cdi
model1 = lm(CDI_18C18C_WG ~ clean_mean_awc , data = clusterAndDistrubtionMeasures)
summary(model1)

model2 = lm(CDI_18C18C_WG ~ clean_mean_awc + avgHourlyPropDrop, data = clusterAndDistrubtionMeasures)
summary(model2)


model1 = lm(ACC_1818 ~ clean_mean_awc , data = clusterAndDistrubtionMeasures)
summary(model1)

model2 = lm(ACC_1818 ~ clusterPerHr, data = clusterAndDistrubtionMeasures)
summary(model2)

model1 = lm(RT18A18C_NO1RT ~ clean_mean_awc , data = clusterAndDistrubtionMeasures)
summary(model1)

model2 = lm(RT18A18C_NO1RT ~ clusterPerHr, data = clusterAndDistrubtionMeasures)
summary(model2)

mean(TL3Metadata$`MomEdu Mom yrs. Education`)



sd(clusterAndDistrubtionMeasures$nclusters)
sd(clusterAndDistrubtionMeasures$avgclustersize)
sd(clusterAndDistrubtionMeasures$clusterPerHr)
sd(clusterAndDistrubtionMeasures$clean_mean_awc)
mean(clusterAndDistrubtionMeasures$nclusters)
mean(clusterAndDistrubtionMeasures$avgclustersize)
mean(clusterAndDistrubtionMeasures$clusterPerHr)
mean(clusterAndDistrubtionMeasures$clean_mean_awc)
summary(clusterAndDistrubtionMeasures)



```


Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
